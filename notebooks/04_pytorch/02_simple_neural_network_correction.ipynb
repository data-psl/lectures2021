{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "02_simple_neural_network_correction.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYDpjIQvptII"
      },
      "source": [
        "# Simple neural network\n",
        "\n",
        "\n",
        "In this notebook, we are going to create and train a simple neural network on the digits dataset using pytorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d331qHuTptIL"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coi5tDrYptIN"
      },
      "source": [
        "First, we need to load the data and make them into pytorch tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "eg0-Y91xptIN",
        "outputId": "355994bf-066e-45f8-a9eb-68660a35f018"
      },
      "source": [
        "X, y = load_digits(return_X_y=True)\n",
        "\n",
        "# Normalize\n",
        "\n",
        "X -= X.mean(axis=0)\n",
        "X /= np.std(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "f, axes = plt.subplots(1, 3)\n",
        "for i, axe in enumerate(axes):\n",
        "    axe.imshow(X[i].reshape(8, 8))\n",
        "\n",
        "x = torch.tensor(X_train).float()\n",
        "y = torch.tensor(y_train).long()\n",
        "n, p = x.shape\n",
        "x_test = torch.tensor(X_test).float()\n",
        "y_test = torch.tensor(y_test).long()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Fl5PPa6ptIN"
      },
      "source": [
        "# Define the network\n",
        "\n",
        "We will work with a simple network with two layers (one hidden layer).\n",
        "\n",
        "The input $x$ is transformed into the output $z$ by the following operations:\n",
        "\n",
        "$$y = \\tanh(W_1x + b_1)$$\n",
        "$$z = W_2y + b_2$$\n",
        "\n",
        "**Exercise 1**: Define a function `net(x, W1, b1, W2, b2)` that implements this transform. Remember that `x` is a matrix of size $n\\times p$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggaCnLEEptIO"
      },
      "source": [
        "def net(x, W1, b1, W2, b2):\n",
        "  # x.shape == (n, p)\n",
        "  # W1.shape == (p, d)\n",
        "  # b1 == (d, )\n",
        "  y = torch.tanh(x @ W1 + b1[None, :])\n",
        "  # y.shape = (n, d)\n",
        "  # W2.shape = (d, N)\n",
        "  z = y @ W2 + b2[None, :]\n",
        "  # z = torch.mm(y, W2) + b2\n",
        "  # z.shape == (n, N)\n",
        "  return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FiobBKkptIO"
      },
      "source": [
        "Next, let us specify the parameters of the network, `W1, b1, W2, b2`. You can chose the size of the hidden layer, but the input and output sizes are determined by the problem.\n",
        "\n",
        "**Exercise 2**: Define a set of parameters `W1, b1, W2, b2`, where you chose the size of the hidden layer. Make sure that all these parameters have their `requires_grad` flag set to true, so that we can compute the gradient with respect to them.\n",
        "\n",
        "In order to check that eveything works, compute `net(x, W1, b1, W2, b2)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkY8VMRQptIP"
      },
      "source": [
        "hidden_size = 20\n",
        "input_size = 64\n",
        "output_size = 10\n",
        "\n",
        "W1 = torch.randn(input_size, hidden_size) / np.sqrt(input_size)\n",
        "W1.requires_grad = True\n",
        "b1 = torch.zeros(hidden_size)\n",
        "b1.requires_grad = True\n",
        "W2 = torch.randn(hidden_size, output_size) / np.sqrt(hidden_size)\n",
        "W2.requires_grad = True\n",
        "b2 = torch.zeros(output_size)\n",
        "b2.requires_grad = True\n",
        "output = net(x, W1, b1, W2, b2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVDAE6bitq8w",
        "outputId": "2817cef9-b272-40c5-fba1-741fad8166dc"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1347, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRXDlmY0ptIQ"
      },
      "source": [
        "Next, we will define a cost function. We will use the classical cross entropy loss. It is imported from pytorch in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzYoC3BKptIQ"
      },
      "source": [
        "from torch.nn.functional import cross_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrEfl1bzptIQ"
      },
      "source": [
        "**Exercise 3**: Compute the current loss of the network, and then back-propagate to compute the gradient with respect to the parameters. Check the gradient with respect to W1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "AYaYHihaptIQ"
      },
      "source": [
        "loss = cross_entropy(input=output, target=y, reduction='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmNQhzP7xlxQ",
        "outputId": "6f5a6c7c-7487-401a-fb18-96c6fc38de3a"
      },
      "source": [
        "loss.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiOqmbtOptIR"
      },
      "source": [
        "We are almost ready to train our network!\n",
        "\n",
        "But first, we will need to compute the accuracy of the network, on the train and test set.\n",
        "\n",
        "**Exercise 4**: Define a function `accuracy(X, y, W1, b1, W2, b2)` that computes the accuracy of the network on the dataset `x`with true labels `y`. Remember that the predicted class at the output of the network is computed as the argmaximum of the output. Compute the current accuracy of the network on the train set. Is it normal ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vx9X9xAybLK"
      },
      "source": [
        "  f = net(x, W1, b1, W2, b2)\n",
        "  pred = torch.argmax(f, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHkS46NRz5cx",
        "outputId": "2a613fe5-df2c-4575-b5fe-ce276a45527f"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1347])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9i7Jy4d0C8P"
      },
      "source": [
        "match = pred == y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB-zUyy00Ov3",
        "outputId": "53e12832-4fb3-4b60-985e-63c7027478b7"
      },
      "source": [
        "match.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1347])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzlpa1AE0TD0",
        "outputId": "1318dd84-b236-402b-8d46-b9734dc6e481"
      },
      "source": [
        "match.float().mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1062)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CFnaUFvptIR",
        "outputId": "e3edd116-a541-466b-82ae-145b019f5f2d"
      },
      "source": [
        "def accuracy(x, y, W1, b1, W2, b2):\n",
        "  f = net(x, W1, b1, W2, b2)\n",
        "  pred = torch.argmax(f, axis=1)\n",
        "  match = pred == y\n",
        "  accuracy = match.float().mean()\n",
        "  return accuracy\n",
        "\n",
        "accuracy(x, y, W1, b1, W2, b2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1062)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuHEvr-HptIR"
      },
      "source": [
        "# Training the network\n",
        "\n",
        "We are now ready to train the network, using back-propagation and stochastic gradient descent.\n",
        "First, we define the number of iterations of the algorithm, the step size, and the batch size. We also reinitialize the weights. Finally, we will store the train and test accuracy during the training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l75G-7UxptIS"
      },
      "source": [
        "n_iter = 1000\n",
        "step_size = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "test_list = []\n",
        "train_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIZDURuPptIS"
      },
      "source": [
        "**Exercise 5**: Complete the following training list, so that each parameter is updated at each iteration.\n",
        "\n",
        "Remember that at each iteration, you should:\n",
        "* compute the output of the network with respect to the batch\n",
        "* Compute the loss, and backpropagate\n",
        "* Update each parameter with gradient descent\n",
        "* Refresh the gradient of each parameter. To do so, you can do:\n",
        "\n",
        "```\n",
        "W1 = W1.detach()\n",
        "W1.requires_grad=True\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtRzH1Vw1_NX",
        "outputId": "93fcb210-1f90-4209-80eb-e5560349ca54"
      },
      "source": [
        "W1.requires_grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5WHj_0T2B0q",
        "outputId": "cc293417-4974-4689-d179-fa7c4412a920"
      },
      "source": [
        "loss."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.4075, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkTAEZoe1dzu"
      },
      "source": [
        "W1.data = W1.data - step_size * W1.grad\n",
        "W1.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i34qSU811tgG",
        "outputId": "2ff02819-3110-4bc0-ab1a-3c15932206ab"
      },
      "source": [
        "W1.requires_grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNO-cnP3ptIS",
        "outputId": "b1d4dca2-68bd-47e7-8ac1-06d963afe317"
      },
      "source": [
        "for i in range(n_iter):\n",
        "    # Selection of the batch here\n",
        "    batch_idx = torch.randperm(n)[:batch_size]\n",
        "    x_batch = x[batch_idx]\n",
        "    y_batch = y[batch_idx]\n",
        "    # YOUR CODE HERE: Compute the output of the network, the loss, and backpropagate\n",
        "    f_batch = net(x_batch, W1, b1, W2, b2)\n",
        "    loss = cross_entropy(f_batch, y_batch)\n",
        "    loss.backward()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      W1.data = W1.data - step_size * W1.grad\n",
        "      W1.grad.zero_()\n",
        "\n",
        "      W2.data = W2.data - step_size * W2.grad\n",
        "      W2.grad.zero_()\n",
        "      \n",
        "      b1.data = b1.data - step_size * b1.grad\n",
        "      b1.grad.zero_()\n",
        "\n",
        "      b2.data = b2.data - step_size * b2.grad\n",
        "      b2.grad.zero_()\n",
        "        \n",
        "    # Utility to print the current state of training\n",
        "    if i % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            train_acc = accuracy(x, y, W1, b1, W2, b2)\n",
        "            test_acc = accuracy(x_test, y_test, W1, b1, W2, b2)\n",
        "        test_list.append(test_acc)\n",
        "        train_list.append(train_acc)\n",
        "        print('Iteration {} Train loss: {:1.3f} Train acc: {:1.3f} Test acc {:1.3f}'.format(i, loss.item(), train_acc, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 Train loss: 2.395 Train acc: 0.146 Test acc 0.133\n",
            "Iteration 10 Train loss: 1.567 Train acc: 0.670 Test acc 0.660\n",
            "Iteration 20 Train loss: 1.109 Train acc: 0.836 Test acc 0.833\n",
            "Iteration 30 Train loss: 0.918 Train acc: 0.880 Test acc 0.891\n",
            "Iteration 40 Train loss: 0.691 Train acc: 0.899 Test acc 0.909\n",
            "Iteration 50 Train loss: 0.618 Train acc: 0.909 Test acc 0.911\n",
            "Iteration 60 Train loss: 0.502 Train acc: 0.918 Test acc 0.920\n",
            "Iteration 70 Train loss: 0.580 Train acc: 0.927 Test acc 0.931\n",
            "Iteration 80 Train loss: 0.455 Train acc: 0.931 Test acc 0.933\n",
            "Iteration 90 Train loss: 0.433 Train acc: 0.931 Test acc 0.940\n",
            "Iteration 100 Train loss: 0.351 Train acc: 0.936 Test acc 0.942\n",
            "Iteration 110 Train loss: 0.334 Train acc: 0.941 Test acc 0.938\n",
            "Iteration 120 Train loss: 0.457 Train acc: 0.948 Test acc 0.944\n",
            "Iteration 130 Train loss: 0.265 Train acc: 0.950 Test acc 0.944\n",
            "Iteration 140 Train loss: 0.188 Train acc: 0.950 Test acc 0.940\n",
            "Iteration 150 Train loss: 0.253 Train acc: 0.952 Test acc 0.953\n",
            "Iteration 160 Train loss: 0.230 Train acc: 0.952 Test acc 0.947\n",
            "Iteration 170 Train loss: 0.187 Train acc: 0.957 Test acc 0.953\n",
            "Iteration 180 Train loss: 0.192 Train acc: 0.961 Test acc 0.956\n",
            "Iteration 190 Train loss: 0.210 Train acc: 0.963 Test acc 0.956\n",
            "Iteration 200 Train loss: 0.149 Train acc: 0.964 Test acc 0.958\n",
            "Iteration 210 Train loss: 0.253 Train acc: 0.966 Test acc 0.951\n",
            "Iteration 220 Train loss: 0.134 Train acc: 0.965 Test acc 0.956\n",
            "Iteration 230 Train loss: 0.242 Train acc: 0.967 Test acc 0.956\n",
            "Iteration 240 Train loss: 0.158 Train acc: 0.971 Test acc 0.958\n",
            "Iteration 250 Train loss: 0.241 Train acc: 0.971 Test acc 0.958\n",
            "Iteration 260 Train loss: 0.213 Train acc: 0.974 Test acc 0.958\n",
            "Iteration 270 Train loss: 0.208 Train acc: 0.973 Test acc 0.958\n",
            "Iteration 280 Train loss: 0.177 Train acc: 0.975 Test acc 0.956\n",
            "Iteration 290 Train loss: 0.159 Train acc: 0.975 Test acc 0.958\n",
            "Iteration 300 Train loss: 0.164 Train acc: 0.975 Test acc 0.956\n",
            "Iteration 310 Train loss: 0.129 Train acc: 0.976 Test acc 0.956\n",
            "Iteration 320 Train loss: 0.093 Train acc: 0.977 Test acc 0.958\n",
            "Iteration 330 Train loss: 0.166 Train acc: 0.978 Test acc 0.958\n",
            "Iteration 340 Train loss: 0.099 Train acc: 0.978 Test acc 0.958\n",
            "Iteration 350 Train loss: 0.134 Train acc: 0.978 Test acc 0.960\n",
            "Iteration 360 Train loss: 0.077 Train acc: 0.979 Test acc 0.960\n",
            "Iteration 370 Train loss: 0.074 Train acc: 0.981 Test acc 0.960\n",
            "Iteration 380 Train loss: 0.107 Train acc: 0.982 Test acc 0.960\n",
            "Iteration 390 Train loss: 0.152 Train acc: 0.982 Test acc 0.960\n",
            "Iteration 400 Train loss: 0.137 Train acc: 0.981 Test acc 0.960\n",
            "Iteration 410 Train loss: 0.139 Train acc: 0.981 Test acc 0.962\n",
            "Iteration 420 Train loss: 0.075 Train acc: 0.981 Test acc 0.962\n",
            "Iteration 430 Train loss: 0.071 Train acc: 0.981 Test acc 0.958\n",
            "Iteration 440 Train loss: 0.100 Train acc: 0.982 Test acc 0.960\n",
            "Iteration 450 Train loss: 0.116 Train acc: 0.982 Test acc 0.960\n",
            "Iteration 460 Train loss: 0.107 Train acc: 0.983 Test acc 0.960\n",
            "Iteration 470 Train loss: 0.083 Train acc: 0.983 Test acc 0.960\n",
            "Iteration 480 Train loss: 0.125 Train acc: 0.984 Test acc 0.960\n",
            "Iteration 490 Train loss: 0.111 Train acc: 0.984 Test acc 0.962\n",
            "Iteration 500 Train loss: 0.075 Train acc: 0.985 Test acc 0.960\n",
            "Iteration 510 Train loss: 0.141 Train acc: 0.984 Test acc 0.962\n",
            "Iteration 520 Train loss: 0.088 Train acc: 0.986 Test acc 0.960\n",
            "Iteration 530 Train loss: 0.199 Train acc: 0.987 Test acc 0.964\n",
            "Iteration 540 Train loss: 0.080 Train acc: 0.986 Test acc 0.964\n",
            "Iteration 550 Train loss: 0.153 Train acc: 0.986 Test acc 0.962\n",
            "Iteration 560 Train loss: 0.132 Train acc: 0.986 Test acc 0.964\n",
            "Iteration 570 Train loss: 0.093 Train acc: 0.986 Test acc 0.964\n",
            "Iteration 580 Train loss: 0.079 Train acc: 0.986 Test acc 0.962\n",
            "Iteration 590 Train loss: 0.056 Train acc: 0.987 Test acc 0.969\n",
            "Iteration 600 Train loss: 0.064 Train acc: 0.987 Test acc 0.967\n",
            "Iteration 610 Train loss: 0.063 Train acc: 0.986 Test acc 0.962\n",
            "Iteration 620 Train loss: 0.101 Train acc: 0.989 Test acc 0.964\n",
            "Iteration 630 Train loss: 0.083 Train acc: 0.988 Test acc 0.964\n",
            "Iteration 640 Train loss: 0.103 Train acc: 0.990 Test acc 0.967\n",
            "Iteration 650 Train loss: 0.097 Train acc: 0.990 Test acc 0.962\n",
            "Iteration 660 Train loss: 0.067 Train acc: 0.989 Test acc 0.962\n",
            "Iteration 670 Train loss: 0.091 Train acc: 0.990 Test acc 0.964\n",
            "Iteration 680 Train loss: 0.104 Train acc: 0.989 Test acc 0.969\n",
            "Iteration 690 Train loss: 0.047 Train acc: 0.990 Test acc 0.969\n",
            "Iteration 700 Train loss: 0.058 Train acc: 0.990 Test acc 0.969\n",
            "Iteration 710 Train loss: 0.090 Train acc: 0.992 Test acc 0.967\n",
            "Iteration 720 Train loss: 0.096 Train acc: 0.992 Test acc 0.967\n",
            "Iteration 730 Train loss: 0.043 Train acc: 0.993 Test acc 0.967\n",
            "Iteration 740 Train loss: 0.057 Train acc: 0.993 Test acc 0.967\n",
            "Iteration 750 Train loss: 0.037 Train acc: 0.993 Test acc 0.967\n",
            "Iteration 760 Train loss: 0.078 Train acc: 0.993 Test acc 0.967\n",
            "Iteration 770 Train loss: 0.053 Train acc: 0.993 Test acc 0.967\n",
            "Iteration 780 Train loss: 0.053 Train acc: 0.993 Test acc 0.969\n",
            "Iteration 790 Train loss: 0.046 Train acc: 0.993 Test acc 0.971\n",
            "Iteration 800 Train loss: 0.067 Train acc: 0.993 Test acc 0.967\n",
            "Iteration 810 Train loss: 0.054 Train acc: 0.993 Test acc 0.967\n",
            "Iteration 820 Train loss: 0.060 Train acc: 0.995 Test acc 0.967\n",
            "Iteration 830 Train loss: 0.038 Train acc: 0.996 Test acc 0.967\n",
            "Iteration 840 Train loss: 0.058 Train acc: 0.996 Test acc 0.967\n",
            "Iteration 850 Train loss: 0.054 Train acc: 0.995 Test acc 0.967\n",
            "Iteration 860 Train loss: 0.043 Train acc: 0.995 Test acc 0.969\n",
            "Iteration 870 Train loss: 0.057 Train acc: 0.995 Test acc 0.967\n",
            "Iteration 880 Train loss: 0.078 Train acc: 0.996 Test acc 0.969\n",
            "Iteration 890 Train loss: 0.040 Train acc: 0.996 Test acc 0.967\n",
            "Iteration 900 Train loss: 0.059 Train acc: 0.996 Test acc 0.967\n",
            "Iteration 910 Train loss: 0.044 Train acc: 0.996 Test acc 0.971\n",
            "Iteration 920 Train loss: 0.048 Train acc: 0.995 Test acc 0.973\n",
            "Iteration 930 Train loss: 0.039 Train acc: 0.995 Test acc 0.973\n",
            "Iteration 940 Train loss: 0.060 Train acc: 0.995 Test acc 0.973\n",
            "Iteration 950 Train loss: 0.028 Train acc: 0.996 Test acc 0.973\n",
            "Iteration 960 Train loss: 0.052 Train acc: 0.996 Test acc 0.971\n",
            "Iteration 970 Train loss: 0.037 Train acc: 0.996 Test acc 0.971\n",
            "Iteration 980 Train loss: 0.032 Train acc: 0.996 Test acc 0.969\n",
            "Iteration 990 Train loss: 0.033 Train acc: 0.996 Test acc 0.969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66OKSmlCptIS"
      },
      "source": [
        "**Exercise 6**: Display the learning curves. You can then play with the network and training parameters:\n",
        "what happens when you change the learning rate, the number of hidden sizes, etc?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydMLaVcF4jVe",
        "outputId": "a1d37907-6bdc-46f4-a6ae-94b9f443211a"
      },
      "source": [
        "test_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.1333),\n",
              " tensor(0.6600),\n",
              " tensor(0.8333),\n",
              " tensor(0.8911),\n",
              " tensor(0.9089),\n",
              " tensor(0.9111),\n",
              " tensor(0.9200),\n",
              " tensor(0.9311),\n",
              " tensor(0.9333),\n",
              " tensor(0.9400),\n",
              " tensor(0.9422),\n",
              " tensor(0.9378),\n",
              " tensor(0.9444),\n",
              " tensor(0.9444),\n",
              " tensor(0.9400),\n",
              " tensor(0.9533),\n",
              " tensor(0.9467),\n",
              " tensor(0.9533),\n",
              " tensor(0.9556),\n",
              " tensor(0.9556),\n",
              " tensor(0.9578),\n",
              " tensor(0.9511),\n",
              " tensor(0.9556),\n",
              " tensor(0.9556),\n",
              " tensor(0.9578),\n",
              " tensor(0.9578),\n",
              " tensor(0.9578),\n",
              " tensor(0.9578),\n",
              " tensor(0.9556),\n",
              " tensor(0.9578),\n",
              " tensor(0.9556),\n",
              " tensor(0.9556),\n",
              " tensor(0.9578),\n",
              " tensor(0.9578),\n",
              " tensor(0.9578),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9622),\n",
              " tensor(0.9622),\n",
              " tensor(0.9578),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9600),\n",
              " tensor(0.9622),\n",
              " tensor(0.9600),\n",
              " tensor(0.9622),\n",
              " tensor(0.9600),\n",
              " tensor(0.9644),\n",
              " tensor(0.9644),\n",
              " tensor(0.9622),\n",
              " tensor(0.9644),\n",
              " tensor(0.9644),\n",
              " tensor(0.9622),\n",
              " tensor(0.9689),\n",
              " tensor(0.9667),\n",
              " tensor(0.9622),\n",
              " tensor(0.9644),\n",
              " tensor(0.9644),\n",
              " tensor(0.9667),\n",
              " tensor(0.9622),\n",
              " tensor(0.9622),\n",
              " tensor(0.9644),\n",
              " tensor(0.9689),\n",
              " tensor(0.9689),\n",
              " tensor(0.9689),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9689),\n",
              " tensor(0.9711),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9689),\n",
              " tensor(0.9667),\n",
              " tensor(0.9689),\n",
              " tensor(0.9667),\n",
              " tensor(0.9667),\n",
              " tensor(0.9711),\n",
              " tensor(0.9733),\n",
              " tensor(0.9733),\n",
              " tensor(0.9733),\n",
              " tensor(0.9733),\n",
              " tensor(0.9711),\n",
              " tensor(0.9711),\n",
              " tensor(0.9689),\n",
              " tensor(0.9689)]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIeai8774lzS",
        "outputId": "30f74668-df31-4adc-d1f5-f795d5cd9c11"
      },
      "source": [
        "train_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.1455),\n",
              " tensor(0.6696),\n",
              " tensor(0.8359),\n",
              " tensor(0.8805),\n",
              " tensor(0.8990),\n",
              " tensor(0.9087),\n",
              " tensor(0.9183),\n",
              " tensor(0.9265),\n",
              " tensor(0.9310),\n",
              " tensor(0.9310),\n",
              " tensor(0.9362),\n",
              " tensor(0.9406),\n",
              " tensor(0.9480),\n",
              " tensor(0.9495),\n",
              " tensor(0.9503),\n",
              " tensor(0.9517),\n",
              " tensor(0.9517),\n",
              " tensor(0.9569),\n",
              " tensor(0.9614),\n",
              " tensor(0.9629),\n",
              " tensor(0.9644),\n",
              " tensor(0.9659),\n",
              " tensor(0.9651),\n",
              " tensor(0.9666),\n",
              " tensor(0.9710),\n",
              " tensor(0.9710),\n",
              " tensor(0.9740),\n",
              " tensor(0.9733),\n",
              " tensor(0.9748),\n",
              " tensor(0.9748),\n",
              " tensor(0.9748),\n",
              " tensor(0.9755),\n",
              " tensor(0.9770),\n",
              " tensor(0.9777),\n",
              " tensor(0.9777),\n",
              " tensor(0.9785),\n",
              " tensor(0.9792),\n",
              " tensor(0.9807),\n",
              " tensor(0.9822),\n",
              " tensor(0.9822),\n",
              " tensor(0.9814),\n",
              " tensor(0.9807),\n",
              " tensor(0.9807),\n",
              " tensor(0.9807),\n",
              " tensor(0.9822),\n",
              " tensor(0.9822),\n",
              " tensor(0.9829),\n",
              " tensor(0.9829),\n",
              " tensor(0.9837),\n",
              " tensor(0.9844),\n",
              " tensor(0.9852),\n",
              " tensor(0.9844),\n",
              " tensor(0.9859),\n",
              " tensor(0.9866),\n",
              " tensor(0.9859),\n",
              " tensor(0.9859),\n",
              " tensor(0.9859),\n",
              " tensor(0.9859),\n",
              " tensor(0.9859),\n",
              " tensor(0.9874),\n",
              " tensor(0.9866),\n",
              " tensor(0.9859),\n",
              " tensor(0.9889),\n",
              " tensor(0.9881),\n",
              " tensor(0.9896),\n",
              " tensor(0.9896),\n",
              " tensor(0.9889),\n",
              " tensor(0.9896),\n",
              " tensor(0.9889),\n",
              " tensor(0.9896),\n",
              " tensor(0.9896),\n",
              " tensor(0.9918),\n",
              " tensor(0.9918),\n",
              " tensor(0.9926),\n",
              " tensor(0.9926),\n",
              " tensor(0.9933),\n",
              " tensor(0.9933),\n",
              " tensor(0.9926),\n",
              " tensor(0.9926),\n",
              " tensor(0.9926),\n",
              " tensor(0.9933),\n",
              " tensor(0.9933),\n",
              " tensor(0.9948),\n",
              " tensor(0.9955),\n",
              " tensor(0.9955),\n",
              " tensor(0.9948),\n",
              " tensor(0.9948),\n",
              " tensor(0.9948),\n",
              " tensor(0.9955),\n",
              " tensor(0.9955),\n",
              " tensor(0.9963),\n",
              " tensor(0.9955),\n",
              " tensor(0.9948),\n",
              " tensor(0.9948),\n",
              " tensor(0.9948),\n",
              " tensor(0.9963),\n",
              " tensor(0.9963),\n",
              " tensor(0.9955),\n",
              " tensor(0.9955),\n",
              " tensor(0.9963)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsNa-qKv4nEQ"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "56PTLuex4sRr",
        "outputId": "46327b89-c976-4323-fa59-166269307f77"
      },
      "source": [
        "plt.plot(train_list, label='Train accuracy')\n",
        "plt.plot(test_list, label='Test accuracy')\n",
        "plt.ylim([0.7, 1])\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f33da850ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUHJbsxq4uh0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}