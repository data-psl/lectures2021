{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch: modules\n",
    "\n",
    "In the previous notebook, we have laboriously trained a neural network written by hand. Pytorch actually contains many modules that make the definition of a network, the data collection and the training very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network module\n",
    "\n",
    "The `torch.nn` module allows to easily define complicated networks. It implements basic linear and convolutional layers, and allows to build with them easily. To do so, we define a `nn.Module` class.\n",
    "\n",
    "This class has two methods:\n",
    "\n",
    "* `__init__` specifies the different layers of the network\n",
    "* `forward` defines how to go from the input to the output using the layers defined in the init.\n",
    "\n",
    "For instance, this is how you would define a simple neural network with one hidden layer of size $100$, that takes $10$ inputs and returns $3$ outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Two_layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(10, 100)\n",
    "        self.layer2 = nn.Linear(100, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = torch.tanh(y)\n",
    "        y = self.layer2(y)\n",
    "        return y \n",
    "    \n",
    "net = Two_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1000, 10)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optim module\n",
    "\n",
    "The `torch.optim` module then allows to easily learn the parameters of the net with backprop. An optimizer, like SGD, takes the parameters of the network as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(lr=1e-2, params=net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then compute a (toy) loss, backpropagate, and use the `optimizer.step` method to make an update:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "y = net(x)\n",
    "loss = y.sum()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is it ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "There are also some convenient tools to load datasets. For instance, we will work with MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the MNIST dataset, the train and testing data, and apply a simple normalizing transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                   transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a loader that will automatically load the images when we train / test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then loop over these loaders to get the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for x, y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    plt.imshow(x[0, 0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to train a network on MNIST ! \n",
    "\n",
    "# Training on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Define a one hidden neural network for MNIST, with a hidden layer of size $1000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Two_layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Your code here\n",
    "    def forward(self, x):\n",
    "        # Your code here\n",
    "    \n",
    "net = Two_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    print(net(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** : Define an SGD optimizer for this network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: Perform one training epoch on the data, and compute the testing accuracy. Use the cross entropy as loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(train_loader):\n",
    "    # You code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_preds = 0\n",
    "for x, y in test_loader:\n",
    "    pred = net(x)\n",
    "    good_preds += (pred.argmax(axis=1) == y).sum().item()\n",
    "\n",
    "print(good_preds / 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get ~ 90% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**: Now, train a convolutionnal network, and try to get the best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Your code here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # your code here\n",
    "    \n",
    "net = CNN()\n",
    "\n",
    "for x, y in train_loader:\n",
    "    print(net(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(train_loader):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_preds = 0\n",
    "for x, y in test_loader:\n",
    "    pred = net(x)\n",
    "    good_preds += (pred.argmax(axis=1) == y).sum().item()\n",
    "\n",
    "print(good_preds / 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**: Put this model on a GPU, and compare the training time.\n",
    "To put a model to GPU, you can to `net.to('cuda')`. The data `x` and `y`should also be put on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3d699a5916e1aff8848f10bc57a89f93bc1cf3a71c02fefcecb8a901731c5d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
